# MuZeroå°çƒAgent - å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ¯ å·²å®Œæˆçš„å®ç°

### âœ… æ ¸å¿ƒç»„ä»¶ï¼ˆ1850+è¡Œä»£ç ï¼‰

| ç»„ä»¶ | æ–‡ä»¶ | åŠŸèƒ½ | çŠ¶æ€ |
|------|------|------|------|
| **æ ¸å¿ƒç½‘ç»œ** | `muzero_core.py` | Representation + Dynamics + Predictionç½‘ç»œ | âœ“ å®Œæˆ |
| **MCTSæœç´¢** | `muzero_mcts.py` | è¿ç»­åŠ¨ä½œç©ºé—´çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢ | âœ“ å®Œæˆ |
| **é‡æ”¾ç¼“å†²** | `muzero_replay.py` | ç»éªŒå›æ”¾å’Œæ•°æ®æ”¶é›† | âœ“ å®Œæˆ |
| **è®­ç»ƒå™¨** | `muzero_trainer.py` | è®­ç»ƒå¾ªç¯å’ŒæŸå¤±å‡½æ•° | âœ“ å®Œæˆ |
| **è®­ç»ƒè„šæœ¬** | `train_muzero.py` | å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆè‡ªæˆ‘å¯¹å¼ˆ+è®­ç»ƒï¼‰ | âœ“ å®Œæˆ |
| **Agentæ¥å£** | `agent.py` (MuZeroAgent) | æ¨ç†æ¥å£ï¼Œå…¼å®¹evaluate.py | âœ“ å®Œæˆ |
| **æµ‹è¯•è„šæœ¬** | `test_muzero.py` | è‡ªåŠ¨åŒ–æµ‹è¯•æ‰€æœ‰ç»„ä»¶ | âœ“ å®Œæˆ |
| **æ–‡æ¡£** | `MUZERO_README.md` | è¯¦ç»†ä½¿ç”¨æ–‡æ¡£ | âœ“ å®Œæˆ |

---

## ğŸš€ 3æ­¥å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1: å®‰è£…ä¾èµ–ï¼ˆ5åˆ†é’Ÿï¼‰

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /home/user/AI3603-Billiards

# å®‰è£…æ‰€æœ‰ä¾èµ–
pip install -r requirements.txt

# å¦‚æœä½ æœ‰GPUï¼ˆå¼ºçƒˆæ¨èï¼‰
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# å¦‚æœåªæœ‰CPU
pip install torch torchvision
```

### æ­¥éª¤2: æµ‹è¯•ç»„ä»¶ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯æ‰€æœ‰ç»„ä»¶
python test_muzero.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MuZeroå®ç°å°±ç»ªã€‚
æ€»è®¡: 6/6 é€šè¿‡
```

### æ­¥éª¤3: å¼€å§‹è®­ç»ƒï¼ˆå‡ å°æ—¶åˆ°å‡ å¤©ï¼‰

#### é€‰é¡¹A: å¿«é€Ÿæµ‹è¯•ï¼ˆ2-4å°æ—¶ï¼ŒCPUå¯ç”¨ï¼‰
```bash
python train_muzero.py \
    --num_epochs 20 \
    --games_per_epoch 3 \
    --batches_per_epoch 20 \
    --num_simulations 20 \
    --batch_size 16
```

#### é€‰é¡¹B: æ ‡å‡†è®­ç»ƒï¼ˆ10-20å°æ—¶ï¼Œéœ€è¦GPUï¼‰
```bash
python train_muzero.py \
    --num_epochs 100 \
    --games_per_epoch 5 \
    --batches_per_epoch 50 \
    --num_simulations 30 \
    --use_gpu \
    --save_interval 5 \
    --eval_interval 10
```

#### é€‰é¡¹C: é«˜è´¨é‡è®­ç»ƒï¼ˆ1-3å¤©ï¼Œéœ€è¦å¼ºGPUï¼‰
```bash
python train_muzero.py \
    --num_epochs 200 \
    --games_per_epoch 10 \
    --batches_per_epoch 100 \
    --num_simulations 50 \
    --batch_size 64 \
    --use_gpu
```

---

## ğŸ“Š ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

### æ–¹æ³•1: åœ¨evaluate.pyä¸­ä½¿ç”¨

ç¼–è¾‘ `evaluate.py`:

```python
from agent import BasicAgent, MuZeroAgent

agent_a = BasicAgent()
agent_b = MuZeroAgent(
    checkpoint_path='checkpoints/latest.pt',  # æˆ– 'checkpoints/epoch_100.pt'
    num_simulations=30,
    temperature=0.0  # è´ªå¿ƒç­–ç•¥ï¼ˆä¸æ¢ç´¢ï¼‰
)
```

è¿è¡Œè¯„ä¼°ï¼š
```bash
python evaluate.py
```

### æ–¹æ³•2: å•ç‹¬æµ‹è¯•

```python
from agent import MuZeroAgent
from poolenv import PoolEnv

# åˆ›å»ºç¯å¢ƒå’Œagent
env = PoolEnv()
agent = MuZeroAgent(checkpoint_path='checkpoints/latest.pt')

# è¿›è¡Œä¸€å±€æ¸¸æˆ
env.reset(target_ball='solid')
while True:
    balls, my_targets, table = env.get_observation()
    action = agent.decision(balls, my_targets, table)
    env.take_shot(action)

    done, info = env.get_done()
    if done:
        print(f"èƒœè€…: {info['winner']}")
        break
```

---

## ğŸ“ è®­ç»ƒè¿›åº¦å‚è€ƒ

### é¢„æœŸèƒœç‡æ›²çº¿ï¼ˆvs BasicAgentï¼‰

```
è½®æ•°     èƒœç‡    è¯´æ˜
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0      25%    éšæœºåˆå§‹åŒ–ï¼Œå‡ ä¹ä¸ä¼šæ‰“
 20      35%    å­¦ä¼šåŸºæœ¬ç‰©ç†è§„å¾‹
 50      50%    å¯ä»¥è¿›çƒï¼Œç®€å•ç­–ç•¥
100      65%    ç†è§£é•¿æœŸè§„åˆ’
200      75%+   è¶…è¶ŠBasicAgent
```

### è®­ç»ƒæ—¥å¿—ç¤ºä¾‹

```
Epoch 10/100
[1/3] è‡ªæˆ‘å¯¹å¼ˆ: 5å±€
  æ¸¸æˆ1: èƒœè€…=A, æ­¥æ•°=15
  æ¸¸æˆ2: èƒœè€…=B, æ­¥æ•°=22
  ...
[2/3] è®­ç»ƒç½‘ç»œ: 50æ‰¹æ¬¡
  å¹³å‡æŸå¤±: total=2.34, value=0.89, reward=0.45, policy=1.00
[3/3] ä¿å­˜æ£€æŸ¥ç‚¹: checkpoints/epoch_10.pt
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒå¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**å¦‚æœæœ‰GPU**:
```bash
# ç¡®ä¿ä½¿ç”¨GPU
python train_muzero.py --use_gpu

# æ£€æŸ¥GPUæ˜¯å¦è¢«ä½¿ç”¨
python -c "import torch; print(torch.cuda.is_available())"
```

**å¦‚æœåªæœ‰CPU**:
```bash
# å‡å°‘æ¨¡æ‹Ÿæ¬¡æ•°å’Œæ‰¹æ¬¡
python train_muzero.py \
    --num_simulations 10 \
    --batches_per_epoch 20 \
    --games_per_epoch 2
```

### Q2: æ˜¾å­˜ä¸è¶³ (CUDA OOM)

```bash
# å‡å°æ‰¹é‡å¤§å°
python train_muzero.py \
    --batch_size 16 \
    --hidden_dim 128
```

### Q3: è®­ç»ƒä¸­æ–­äº†æ€ä¹ˆåŠï¼Ÿ

```bash
# ä»æ£€æŸ¥ç‚¹æ¢å¤
python train_muzero.py --resume --use_gpu
```

### Q4: å¦‚ä½•æŸ¥çœ‹è®­ç»ƒè¿›åº¦ï¼Ÿ

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ï¼š
- ä¿å­˜æ£€æŸ¥ç‚¹åˆ° `checkpoints/` ç›®å½•
- æ¯10è½®è¿›è¡Œä¸€æ¬¡è¯„ä¼°ï¼ˆå¦‚æœè®¾ç½®äº† `--eval_interval 10`ï¼‰
- æ‰“å°æŸå¤±å€¼

æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼š
```
checkpoints/
â”œâ”€â”€ latest.pt          # æœ€æ–°æ¨¡å‹
â”œâ”€â”€ latest_buffer.pkl  # é‡æ”¾ç¼“å†²åŒº
â”œâ”€â”€ epoch_10.pt        # ç¬¬10è½®
â”œâ”€â”€ epoch_20.pt        # ç¬¬20è½®
â””â”€â”€ ...
```

### Q5: æ¨¡å‹è¡¨ç°ä¸å¥½ï¼Ÿ

**è°ƒæ•´è¶…å‚æ•°**:
```bash
# å¢åŠ æ¢ç´¢
--temperature 1.0  # è®­ç»ƒæ—¶
--temperature 0.0  # è¯„ä¼°æ—¶

# å¢åŠ æœç´¢æ·±åº¦
--num_simulations 50

# å¢åŠ è®­ç»ƒæ•°æ®
--games_per_epoch 10
--replay_buffer_size 1000
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### ç¡¬ä»¶è¦æ±‚

| é…ç½® | æœ€å° | æ¨è | æœ€ä¼˜ |
|------|------|------|------|
| CPU | i5 | i7 | ä¸é™ |
| RAM | 8GB | 16GB | 32GB+ |
| GPU | æ—  | GTX 1060 6GB | RTX 3060+ |
| å­˜å‚¨ | 5GB | 10GB | 20GB+ |

### è®­ç»ƒæ—¶é—´ä¼°ç®—

| é…ç½® | 20è½® | 100è½® | 200è½® |
|------|------|-------|-------|
| CPU only | 4å°æ—¶ | 20å°æ—¶ | 40å°æ—¶ |
| GTX 1060 | 1å°æ—¶ | 5å°æ—¶ | 10å°æ—¶ |
| RTX 3060 | 30åˆ†é’Ÿ | 2.5å°æ—¶ | 5å°æ—¶ |
| RTX 4090 | 15åˆ†é’Ÿ | 1å°æ—¶ | 2å°æ—¶ |

### æ¨ç†é€Ÿåº¦

| MCTSæ¨¡æ‹Ÿæ¬¡æ•° | CPU | GPU |
|-------------|-----|-----|
| 10æ¬¡ | 5ç§’ | 2ç§’ |
| 30æ¬¡ | 15ç§’ | 5ç§’ |
| 50æ¬¡ | 25ç§’ | 8ç§’ |

---

## ğŸ¯ è¿›é˜¶ä½¿ç”¨

### è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°

ç¼–è¾‘ `muzero_replay.py` ä¸­çš„ `compute_reward_from_step_info`:

```python
def compute_reward_from_step_info(step_info, player_targets, balls_before, balls_after):
    reward = 0.0

    # åŸºç¡€å¥–åŠ±
    reward += len(step_info.get('ME_INTO_POCKET', [])) * 50
    reward -= step_info.get('WHITE_BALL_INTO_POCKET', False) * 100

    # æ·»åŠ è‡ªå®šä¹‰å¥–åŠ±
    # ä¾‹å¦‚ï¼šè·ç¦»çƒè¢‹è¿‘çš„å¥–åŠ±
    reward += proximity_bonus(balls_after, player_targets)

    # ä¾‹å¦‚ï¼šç™½çƒä½ç½®å¥½çš„å¥–åŠ±
    reward += position_bonus(balls_after['cue'])

    return reward
```

### æ··åˆè®­ç»ƒç­–ç•¥

```python
# å…ˆä¸BasicAgentå¯¹æˆ˜æ”¶é›†æ•°æ®
for epoch in range(50):
    play_against(BasicAgent())
    train()

# å†è‡ªæˆ‘å¯¹å¼ˆç²¾ç»†è°ƒæ•´
for epoch in range(50, 100):
    self_play()
    train()
```

### å¯¼å‡ºæ¨¡å‹

```python
import torch
from muzero_core import MuZeroNetwork

# åŠ è½½æ¨¡å‹
network = MuZeroNetwork()
checkpoint = torch.load('checkpoints/latest.pt')
network.load_state_dict(checkpoint['network_state_dict'])

# å¯¼å‡ºä¸ºONNXï¼ˆè·¨å¹³å°éƒ¨ç½²ï¼‰
dummy_input = torch.randn(1, 83)
torch.onnx.export(network.representation, dummy_input, 'muzero_repr.onnx')
```

---

## ğŸ“š æ›´å¤šèµ„æº

- **è¯¦ç»†æ–‡æ¡£**: æŸ¥çœ‹ `MUZERO_README.md`
- **æµ‹è¯•è„šæœ¬**: è¿è¡Œ `python test_muzero.py`
- **åŸå§‹è®ºæ–‡**: [MuZero Paper](https://arxiv.org/abs/1911.08265)

---

## ğŸ‰ æ€»ç»“

ä½ ç°åœ¨æ‹¥æœ‰ï¼š

âœ… **å®Œæ•´çš„MuZeroå®ç°** (1850+è¡Œä»£ç )
âœ… **å³æ’å³ç”¨çš„è®­ç»ƒè„šæœ¬**
âœ… **è‡ªåŠ¨åŒ–æµ‹è¯•å¥—ä»¶**
âœ… **è¯¦ç»†çš„ä½¿ç”¨æ–‡æ¡£**

**ä¸‹ä¸€æ­¥**ï¼š
1. å®‰è£…ä¾èµ–: `pip install -r requirements.txt`
2. æµ‹è¯•ç»„ä»¶: `python test_muzero.py`
3. å¼€å§‹è®­ç»ƒ: `python train_muzero.py --num_epochs 20`
4. è¯„ä¼°æ¨¡å‹: ä¿®æ”¹ `evaluate.py` å¹¶è¿è¡Œ

**ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼ğŸš€**
